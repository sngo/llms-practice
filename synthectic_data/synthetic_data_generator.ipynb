{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyP//hkj+p0BeLzt2rxkwrwZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sngo/llms-practice/blob/main/synthectic_data/synthetic_data_generator.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "-cB8cu1M28c_"
      },
      "outputs": [],
      "source": [
        "!pip install -q gradio>=4.0.0 anthropic>=0.18.0 pandas>=2.0.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import csv\n",
        "import time\n",
        "import tempfile\n",
        "import gradio as gr\n",
        "import anthropic\n",
        "import pandas as pd\n",
        "import sqlite3\n",
        "from openai import OpenAI\n",
        "from typing import Dict, List, Any, Optional, Union\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "ePg47mYB5EL_"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "AEqHSNhE5OD9"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SyntheticDataGenerator:\n",
        "    def __init__(self, api_key: Optional[str] = None):\n",
        "        \"\"\"Initialize the SyntheticDataGenerator with API key.\"\"\"\n",
        "        self.api_key = api_key or userdata.get('OPENAI_API_KEY')\n",
        "        if not self.api_key:\n",
        "            raise ValueError(\"OPENAI API key is required\")\n",
        "\n",
        "        self.client = OpenAI(api_key=self.api_key)\n",
        "        self.model = \"gpt-4o-mini\"  # Default model\n",
        "\n",
        "    def set_model(self, model_name: str) -> None:\n",
        "        \"\"\"Set the model to use.\"\"\"\n",
        "        self.model = model_name\n",
        "        return f\"Model set to: {self.model}\"\n",
        "\n",
        "    def validate_schema(self, schema: Dict[str, Any]) -> bool:\n",
        "        \"\"\"Validate that the schema is properly formatted.\"\"\"\n",
        "        required_keys = [\"name\", \"fields\"]\n",
        "        if not all(key in schema for key in required_keys):\n",
        "            return False, f\"Schema missing required keys: {required_keys}\"\n",
        "\n",
        "        if not isinstance(schema[\"fields\"], list) or len(schema[\"fields\"]) == 0:\n",
        "            return False, \"Schema must contain a non-empty 'fields' list\"\n",
        "\n",
        "        for field in schema[\"fields\"]:\n",
        "            if \"name\" not in field or \"type\" not in field:\n",
        "                return False, f\"Each field must have 'name' and 'type' attributes: {field}\"\n",
        "\n",
        "        return True, \"Schema is valid\"\n",
        "\n",
        "    def generate_prompt(self, schema: Dict[str, Any], num_records: int, special_instructions: Optional[str] = None) -> str:\n",
        "        \"\"\"Create a prompt for model to generate synthetic data based on schema.\"\"\"\n",
        "        fields_info = \"\\n\".join([f\"- {field['name']} ({field['type']}): {field.get('description', '')}\"\n",
        "                              for field in schema[\"fields\"]])\n",
        "\n",
        "        constraints = schema.get(\"constraints\", [])\n",
        "        constraints_text = \"\"\n",
        "        if constraints:\n",
        "            constraints_text = \"Apply these constraints:\\n\" + \"\\n\".join([f\"- {c}\" for c in constraints])\n",
        "\n",
        "        additional_instructions = special_instructions or schema.get(\"additional_instructions\", \"\")\n",
        "\n",
        "        prompt = f\"\"\"\n",
        "        I need you to generate {num_records} records of synthetic test data according to this schema:\n",
        "\n",
        "        Dataset: {schema[\"name\"]}\n",
        "\n",
        "        Fields:\n",
        "        {fields_info}\n",
        "\n",
        "        {constraints_text}\n",
        "\n",
        "        {additional_instructions}\n",
        "\n",
        "        Important guidelines:\n",
        "        1. Generate realistic but completely fictional data\n",
        "        2. Ensure internal consistency across fields when logical relationships exist\n",
        "        3. Provide appropriate variety and distribution of values\n",
        "        4. Format the output as a JSON array of objects with each field name as the key\n",
        "        5. Only return the raw JSON data with no additional explanations\n",
        "\n",
        "        Output the synthetic data as valid JSON that I can parse:\n",
        "        \"\"\"\n",
        "\n",
        "        return prompt\n",
        "\n",
        "    def generate_data(self, schema: Dict[str, Any], num_records: int = 10,\n",
        "                     special_instructions: Optional[str] = None, max_retries: int = 3) -> List[Dict[str, Any]]:\n",
        "        \"\"\"Generate synthetic data using Claude API.\"\"\"\n",
        "        prompt = self.generate_prompt(schema, num_records, special_instructions)\n",
        "\n",
        "        progress_text = f\"Generating {num_records} synthetic records with {self.model}...\"\n",
        "\n",
        "        for attempt in range(max_retries):\n",
        "            try:\n",
        "                response = self.client.chat.completions.create(\n",
        "                    model=self.model,\n",
        "                    max_tokens=4000,\n",
        "                    messages=[\n",
        "                        {\"role\": \"user\", \"content\": prompt}\n",
        "                    ],\n",
        "                    temperature=0.7,\n",
        "                )\n",
        "\n",
        "                # Extract JSON content\n",
        "                content = response.choices[0].message.content\n",
        "                # Look for JSON in the content\n",
        "                json_start = content.find('[')\n",
        "                json_end = content.rfind(']') + 1\n",
        "\n",
        "                if json_start >= 0 and json_end > json_start:\n",
        "                    json_str = content[json_start:json_end]\n",
        "                    data = json.loads(json_str)\n",
        "                    return data, f\"Successfully generated {len(data)} records\"\n",
        "                else:\n",
        "                    error_msg = \"No valid JSON array found in response. Retrying...\"\n",
        "                    if attempt == max_retries - 1:\n",
        "                        return None, f\"Failed: {error_msg} Response content: {content[:100]}...\"\n",
        "            except json.JSONDecodeError:\n",
        "                error_msg = f\"Failed to parse JSON (Attempt {attempt+1}/{max_retries})\"\n",
        "                if attempt == max_retries - 1:\n",
        "                    return None, f\"Failed: {error_msg} - Raw response: {content[:500]}...\"\n",
        "            except Exception as e:\n",
        "                error_msg = f\"API error (Attempt {attempt+1}/{max_retries}): {str(e)}\"\n",
        "                if attempt == max_retries - 1:\n",
        "                    return None, f\"Failed: {error_msg}\"\n",
        "                time.sleep(2)  # Wait before retrying\n",
        "\n",
        "        return None, f\"Failed to generate valid data after {max_retries} attempts\"\n",
        "\n",
        "    def save_data(self, data: List[Dict[str, Any]], output_format: str, file_path: str = None, table_name: str = \"synthetic_data\"):\n",
        "        \"\"\"Save the generated data in the specified format.\"\"\"\n",
        "        if not data:\n",
        "            return None, \"No data to save\"\n",
        "\n",
        "        if output_format == \"json\":\n",
        "            if not file_path:\n",
        "                # Create a temporary file for download\n",
        "                with tempfile.NamedTemporaryFile(delete=False, suffix='.json') as tmp:\n",
        "                    file_path = tmp.name\n",
        "                    json.dump(data, tmp, indent=2)\n",
        "            else:\n",
        "                with open(file_path, 'w') as f:\n",
        "                    json.dump(data, f, indent=2)\n",
        "            return file_path, f\"Saved {len(data)} records as JSON\"\n",
        "\n",
        "        elif output_format == \"csv\":\n",
        "            if not file_path:\n",
        "                with tempfile.NamedTemporaryFile(delete=False, suffix='.csv') as tmp:\n",
        "                    file_path = tmp.name\n",
        "\n",
        "            keys = data[0].keys()\n",
        "            with open(file_path, 'w', newline='') as output_file:\n",
        "                dict_writer = csv.DictWriter(output_file, fieldnames=keys)\n",
        "                dict_writer.writeheader()\n",
        "                dict_writer.writerows(data)\n",
        "            return file_path, f\"Saved {len(data)} records as CSV\"\n",
        "\n",
        "        elif output_format == \"sqlite\":\n",
        "            if not file_path:\n",
        "                with tempfile.NamedTemporaryFile(delete=False, suffix='.db') as tmp:\n",
        "                    file_path = tmp.name\n",
        "\n",
        "            df = pd.DataFrame(data)\n",
        "            conn = sqlite3.connect(file_path)\n",
        "            df.to_sql(table_name, conn, if_exists='replace', index=False)\n",
        "            conn.close()\n",
        "            return file_path, f\"Saved {len(data)} records to SQLite database, table {table_name}\"\n",
        "\n",
        "        elif output_format == \"dataframe\":\n",
        "            # Return as pandas DataFrame for display in Gradio\n",
        "            df = pd.DataFrame(data)\n",
        "            return df, f\"Generated {len(data)} records\"\n",
        "\n",
        "        else:\n",
        "            return None, f\"Unsupported format: {output_format}\"\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NNW4ENIG5ed9"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Sample schema for the UI\n",
        "SAMPLE_SCHEMA = \"\"\"{\n",
        "  \"name\": \"Users Test Dataset\",\n",
        "  \"description\": \"Synthetic user data for application testing\",\n",
        "  \"fields\": [\n",
        "    {\n",
        "      \"name\": \"id\",\n",
        "      \"type\": \"uuid\",\n",
        "      \"description\": \"Unique identifier for each user\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"first_name\",\n",
        "      \"type\": \"string\",\n",
        "      \"description\": \"User's first name\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"last_name\",\n",
        "      \"type\": \"string\",\n",
        "      \"description\": \"User's last name\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"email\",\n",
        "      \"type\": \"email\",\n",
        "      \"description\": \"User's email address\"\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"age\",\n",
        "      \"type\": \"integer\",\n",
        "      \"description\": \"User's age in years\",\n",
        "      \"min\": 18,\n",
        "      \"max\": 85\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"subscription_tier\",\n",
        "      \"type\": \"enum\",\n",
        "      \"description\": \"User's subscription level\",\n",
        "      \"values\": [\"free\", \"basic\", \"premium\", \"enterprise\"]\n",
        "    },\n",
        "    {\n",
        "      \"name\": \"is_active\",\n",
        "      \"type\": \"boolean\",\n",
        "      \"description\": \"Whether the user account is active\"\n",
        "    }\n",
        "  ],\n",
        "  \"constraints\": [\n",
        "    \"If age is under 25, subscription_tier should be more likely to be 'free' or 'basic'\",\n",
        "    \"80% of users should have is_active set to true\"\n",
        "  ],\n",
        "  \"additional_instructions\": \"Create diverse users with varied names and realistic data patterns.\"\n",
        "}\"\"\""
      ],
      "metadata": {
        "id": "Fu7Vm2kz5v81"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generator = SyntheticDataGenerator()"
      ],
      "metadata": {
        "id": "Yqx6H6Fx_Hms"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generated_data = generator.generate_data(json.loads(SAMPLE_SCHEMA), num_records=10)"
      ],
      "metadata": {
        "id": "pQR2wA29_X5y"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generated_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iJXJt9Wd_b1G",
        "outputId": "0fd3c347-8728-4e3a-8963-676994e755b2"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "([{'id': 'd9e0b1f9-efb3-4c8e-8cfd-8b3a2e1f1b9a', 'first_name': 'Liam', 'last_name': 'Smith', 'email': 'liam.smith@example.com', 'age': 22, 'subscription_tier': 'free', 'is_active': True}, {'id': '5c5c3b3e-5da2-4f49-9f38-08de5a9b2b59', 'first_name': 'Emma', 'last_name': 'Johnson', 'email': 'emma.johnson@example.com', 'age': 28, 'subscription_tier': 'premium', 'is_active': True}, {'id': '1c4c4c3e-18db-4b58-a4e5-2d3c9f3e7a2d', 'first_name': 'Olivia', 'last_name': 'Williams', 'email': 'olivia.williams@example.com', 'age': 20, 'subscription_tier': 'basic', 'is_active': True}, {'id': 'b8c1f3a1-5d4f-4b6b-b3a8-e3d1a1f3b9b2', 'first_name': 'Noah', 'last_name': 'Jones', 'email': 'noah.jones@example.com', 'age': 35, 'subscription_tier': 'standard', 'is_active': False}, {'id': 'a5f1b2d9-1d39-4b4e-b4a9-6d5c5a7c2c3d', 'first_name': 'Ava', 'last_name': 'Brown', 'email': 'ava.brown@example.com', 'age': 24, 'subscription_tier': 'free', 'is_active': True}, {'id': '1a4e1b0b-5c3f-4a8a-b9c9-8b0c8d1e4a6f', 'first_name': 'Elijah', 'last_name': 'Davis', 'email': 'elijah.davis@example.com', 'age': 30, 'subscription_tier': 'premium', 'is_active': True}, {'id': 'c2b2e4d8-4b9e-4b4e-8e9a-8f2c4f1b2e3d', 'first_name': 'Sophia', 'last_name': 'Miller', 'email': 'sophia.miller@example.com', 'age': 19, 'subscription_tier': 'basic', 'is_active': True}, {'id': '4b2c1f9a-8c3e-4a8e-ae9c-2b4c8a6b1b2f', 'first_name': 'James', 'last_name': 'Garcia', 'email': 'james.garcia@example.com', 'age': 40, 'subscription_tier': 'standard', 'is_active': False}, {'id': '3e5d7b1e-1f4e-4f39-b9a4-0a6b2f1a6d3c', 'first_name': 'Isabella', 'last_name': 'Martinez', 'email': 'isabella.martinez@example.com', 'age': 23, 'subscription_tier': 'free', 'is_active': True}, {'id': '7c4f5c9a-9f5e-4c3a-8b2c-9a1b2c3d4e5f', 'first_name': 'Mason', 'last_name': 'Rodriguez', 'email': 'mason.rodriguez@example.com', 'age': 32, 'subscription_tier': 'premium', 'is_active': True}], 'Successfully generated 10 records')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_schema_input(schema_text):\n",
        "    \"\"\"Validate the schema JSON.\"\"\"\n",
        "    try:\n",
        "        schema = json.loads(schema_text)\n",
        "        is_valid, message = generator.validate_schema(schema)\n",
        "        return message\n",
        "    except json.JSONDecodeError as e:\n",
        "        return f\"Invalid JSON: {str(e)}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ],
      "metadata": {
        "id": "DLBIHsZT_gzq"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "validate_schema_input(SAMPLE_SCHEMA)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "GhvKG18G_ziB",
        "outputId": "47ddb0ba-2e99-4e6d-934b-14ba71b22879"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"Each field must have 'name' and 'type' attributes: {'type': 'boolean', 'description': 'Whether the user account is active'}\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_synthetic_data(schema_text, num_records, special_instructions):\n",
        "    \"\"\"Generate synthetic data based on the inputs.\"\"\"\n",
        "    global last_generated_data\n",
        "\n",
        "    try:\n",
        "\n",
        "        # Parse the schema\n",
        "        schema = json.loads(schema_text)\n",
        "        is_valid, message = generator.validate_schema(schema)\n",
        "        if not is_valid:\n",
        "            return None, message\n",
        "\n",
        "        # Generate the data\n",
        "        data, message = generator.generate_data(\n",
        "            schema,\n",
        "            num_records=int(num_records),\n",
        "            special_instructions=special_instructions\n",
        "        )\n",
        "\n",
        "        if data:\n",
        "            last_generated_data = data\n",
        "            # Convert to DataFrame for display\n",
        "            df = pd.DataFrame(data)\n",
        "            return df, message\n",
        "        else:\n",
        "            return None, message\n",
        "\n",
        "    except json.JSONDecodeError as e:\n",
        "        return None, f\"Invalid schema JSON: {str(e)}\"\n",
        "    except Exception as e:\n",
        "        return None, f\"Error generating data: {str(e)}\""
      ],
      "metadata": {
        "id": "YiMf_-RY_-Og"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def save_and_download_data(output_format, table_name):\n",
        "    \"\"\"Save the generated data in the selected format and prepare for download.\"\"\"\n",
        "    global last_generated_data\n",
        "\n",
        "    if last_generated_data is None:\n",
        "        return None, \"No data has been generated yet\"\n",
        "\n",
        "    try:\n",
        "        file_path, message = generator.save_data(\n",
        "            last_generated_data,\n",
        "            output_format,\n",
        "            table_name=table_name\n",
        "        )\n",
        "        return file_path, message\n",
        "    except Exception as e:\n",
        "        return None, f\"Error saving data: {str(e)}\""
      ],
      "metadata": {
        "id": "OvlW4ATtAjIp"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Gradio interface\n",
        "with gr.Blocks(title=\"Synthetic Data Generator\") as app:\n",
        "    gr.Markdown(\"# Synthetic Testing Data Generator\")\n",
        "    gr.Markdown(\"Generate realistic synthetic data using OpenAI model\")\n",
        "\n",
        "    with gr.Tab(\"Generate Data\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column(scale=1):\n",
        "                num_records_slider = gr.Slider(\n",
        "                    minimum=1,\n",
        "                    maximum=100,\n",
        "                    value=10,\n",
        "                    step=1,\n",
        "                    label=\"Number of Records\"\n",
        "                )\n",
        "\n",
        "                schema_validate_btn = gr.Button(\"Validate Schema\")\n",
        "                generate_btn = gr.Button(\"Generate Data\", variant=\"primary\")\n",
        "\n",
        "            with gr.Column(scale=2):\n",
        "                schema_input = gr.Textbox(\n",
        "                    label=\"Data Schema (JSON)\",\n",
        "                    placeholder=\"Paste your schema here...\",\n",
        "                    value=SAMPLE_SCHEMA,\n",
        "                    lines=20\n",
        "                )\n",
        "\n",
        "                special_instructions = gr.Textbox(\n",
        "                    label=\"Additional Instructions (Optional)\",\n",
        "                    placeholder=\"Any special requirements for data generation\",\n",
        "                    lines=2\n",
        "                )\n",
        "\n",
        "        with gr.Row():\n",
        "            status_output = gr.Textbox(label=\"Status\", interactive=False)\n",
        "\n",
        "        with gr.Row():\n",
        "            data_output = gr.DataFrame(label=\"Generated Data\")\n",
        "\n",
        "    with gr.Tab(\"Download Data\"):\n",
        "        with gr.Row():\n",
        "            with gr.Column():\n",
        "                output_format = gr.Radio(\n",
        "                    choices=[\"json\", \"csv\", \"sqlite\"],\n",
        "                    label=\"Output Format\",\n",
        "                    value=\"json\"\n",
        "                )\n",
        "\n",
        "                table_name = gr.Textbox(\n",
        "                    label=\"Table Name (for SQLite)\",\n",
        "                    value=\"synthetic_data\"\n",
        "                )\n",
        "\n",
        "                download_btn = gr.Button(\"Prepare for Download\", variant=\"primary\")\n",
        "\n",
        "            with gr.Column():\n",
        "                download_status = gr.Textbox(label=\"Download Status\", interactive=False)\n",
        "                download_file = gr.File(label=\"Download File\")\n",
        "\n",
        "    # Wire up the components\n",
        "    schema_validate_btn.click(validate_schema_input, inputs=[schema_input], outputs=[status_output])\n",
        "\n",
        "    generate_btn.click(\n",
        "        generate_synthetic_data,\n",
        "        inputs=[schema_input, num_records_slider, special_instructions],\n",
        "        outputs=[data_output, status_output]\n",
        "    )\n",
        "\n",
        "    download_btn.click(\n",
        "        save_and_download_data,\n",
        "        inputs=[output_format, table_name],\n",
        "        outputs=[download_file, download_status]\n",
        "    )"
      ],
      "metadata": {
        "id": "B2AEeHD0AqqT"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "view = app.launch(share=True, debug=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "id": "M5Ck1QylCbKY",
        "outputId": "efafeae5-bdd0-453b-ba6d-2d96cc5153ce"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://9009225dd55f7eb32c.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://9009225dd55f7eb32c.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://9009225dd55f7eb32c.gradio.live\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lIWjl0GCCqPp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}