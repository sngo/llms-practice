{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPlvcEGYCYqtVlTnfpaPnWL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sngo/llms-practice/blob/main/Code_Explain.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wE-eZom6scF5"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import requests\n",
        "import json\n",
        "from typing import List\n",
        "from bs4 import BeautifulSoup\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "Msf7_YgptCBj"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MODEL_GPT = 'gpt-4o-mini'"
      ],
      "metadata": {
        "id": "5PYnvJXUtJ_f"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "system_prompt = \"You are a coding expert. Your task is to analyze code fragments and provide helpful, accurate responses based on their content. \"\n",
        "system_prompt += \"Your analysis may include explanations, improvements, bug fixes, or suggestions, depending on what the code requires.\\n\"\n",
        "\n",
        "system_prompt += \"Respond in markdown format for clarity and readability.\""
      ],
      "metadata": {
        "id": "usqx3vpZtMko"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def code_user_prompt(input):\n",
        "  user_prompt = input\n",
        "  user_prompt = user_prompt[:2000]\n",
        "  return user_prompt"
      ],
      "metadata": {
        "id": "EWiU8zSzulXY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from IPython.display import display, Markdown, update_display\n",
        "\n",
        "def display_stream(response):\n",
        "  \"\"\"Displays the response stream from OpenAI API.\"\"\"\n",
        "\n",
        "  # Create a display handle to update\n",
        "  handle = display(Markdown(\"\"), display_id=True)\n",
        "\n",
        "  # Iterate through the stream of tokens\n",
        "  content = \"\"\n",
        "  for chunk in response:\n",
        "    if chunk.choices and chunk.choices[0].delta and chunk.choices[0].delta.content:\n",
        "      content += chunk.choices[0].delta.content\n",
        "      handle.update(Markdown(content))  # Update the displayed content\n",
        "\n",
        "      # Optional: Introduce a small delay for better visualization\n",
        "      time.sleep(0.02)\n",
        "\n",
        "# Assuming you have obtained the 'response' object using OpenAI API\n",
        "# ... your OpenAI API call ...\n",
        "\n",
        "# Call the display_stream function to display the streaming response\n",
        "#display_stream(response)"
      ],
      "metadata": {
        "id": "6guhkjRW0ZOX"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def analyze_code(code: str):\n",
        "  response = OpenAI(api_key=api_key).chat.completions.create(\n",
        "    model=MODEL_GPT,\n",
        "    messages=[\n",
        "      {\"role\": \"system\", \"content\": system_prompt},\n",
        "      {\"role\": \"user\", \"content\": code_user_prompt(code)}\n",
        "    ],\n",
        "    stream=True\n",
        "  )\n",
        "  #result = response.choices[0].message.content\n",
        "  #display(Markdown(result))\n",
        "  display_stream(response)\n",
        "\n"
      ],
      "metadata": {
        "id": "k891OeTvvAmp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "analyze_code(\"Please explain what this code does and why:yield from {book.get(\\\"author\\\") for book in books if book.get(\\\"author\\\")}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 916
        },
        "id": "bLdkDNJGveZB",
        "outputId": "d9708c75-f34f-470a-b197-d663b24cce24"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "Certainly! Let's break down the code snippet you provided:\n\n```python\nyield from {book.get(\"author\") for book in books if book.get(\"author\")}\n```\n\n### Explanation\n\nThis line of code is using a **generator function** with the `yield from` statement in Python, and it's also leveraging a **set comprehension** to create a set of authors from a collection of books. Let's dissect it in detail:\n\n1. **Set Comprehension**:\n    - `{book.get(\"author\") for book in books if book.get(\"author\")}` is a set comprehension that generates a set of authors from the `books` collection.\n    - `book.get(\"author\")` attempts to retrieve the value associated with the key `\"author\"` from each `book` dictionary.\n    - The `if book.get(\"author\")` clause serves as a filter: it ensures that only books with a non-None and non-empty author value are included in the resulting set.\n    - The use of a set comprehension (enclosed in `{}`) suggests that the code is interested in distinct authors, as sets inherently do not allow duplicate entries.\n\n2. **Yield from**:\n    - `yield from` is used here to yield all the values from the set created by the comprehension. This is a way of yielding multiple values from a generator function without needing to loop through the set explicitly.\n    - This means that each author will be yielded one at a time, allowing the caller of the generator to iterate through them.\n\n### Why itâ€™s used\n\n- **Efficiency**: Using `yield from` allows the function to be more memory-efficient because it does not need to store all authors in a list; it generates them on-the-fly.\n- **Uniqueness**: By using a set comprehension, the code ensures that no duplicate authors are yielded, which can be particularly useful if the `books` list contains multiple entries with the same author.\n- **Readability**: The structure is concise and utilizes Python's powerful comprehension syntax, making it clear that the intention is to collect distinct authors from the input data.\n\n### Example Usage\n\nIf you had a list of book dictionaries like this:\n\n```python\nbooks = [\n    {\"title\": \"Book One\", \"author\": \"Author A\"},\n    {\"title\": \"Book Two\", \"author\": \"Author B\"},\n    {\"title\": \"Book Three\", \"author\": \"Author A\"},\n    {\"title\": \"Book Four\", \"author\": None},\n    {\"title\": \"Book Five\", \"author\": \"\"}\n]\n```\n\nUsing the provided code snippet in a generator function would yield:\n\n- \"Author A\"\n- \"Author B\"\n\nThe duplicates and entries with `None` or empty strings would not be included in the output.\n\n### Improvement Suggestion\n\nIf you also want to handle cases where the author's value might be an empty string differently, you could further refine the filter in the set comprehension e.g.:\n\n```python\nyield from {book[\"author\"] for book in books if book.get(\"author\")}\n```\n\nThis would yield authors only if they are truthy, which accounts for both `None` and empty string cases effectively."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ujKNd5o3wCO2"
      },
      "execution_count": 8,
      "outputs": []
    }
  ]
}